Make sure the LiteLLM database is up at https://supabase.com/dashboard/project/swsgzmosghmlfbcuhqnp
Run the LiteLLM proxy with `litellm --model gpt-4.1-mini`, and see UI at http://localhost:4000/ui
Run `main.py` using the `.env` as a source, which contains tokens for the bot AND the LiteLLM proxy
